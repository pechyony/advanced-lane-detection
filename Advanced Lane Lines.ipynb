{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pairs of image and object points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_dir = 'output_images/object_points/'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    \n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "row_corners = 9\n",
    "col_corners = 6\n",
    "objp = np.zeros((row_corners*col_corners,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:row_corners, 0:col_corners].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/cal*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (row_corners,col_corners), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (row_corners,col_corners), corners, ret)\n",
    "        write_name = out_dir + fname.split('\\\\')[-1]\n",
    "        cv2.imwrite(write_name, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute calibration matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do camera calibration given object points and image points\n",
    "img = cv2.imread('camera_cal/calibration1.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply a distortion correction to calibration images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_dir = 'output_images/calibrated_images/'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    \n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    cv2.imwrite(out_dir + fname.split('\\\\')[-1],dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a distortion correction to test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_dir = 'output_images/undistorted_images/'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    \n",
    "# Make a list of calibration images\n",
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    cv2.imwrite(out_dir + fname.split('\\\\')[-1],dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use color transforms, gradients, etc., to create a thresholded binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_binary_image(img, s_thresh=(90, 255), sx_thresh=(20, 100), l_thresh=(50, 255)):\n",
    "    \"\"\"\n",
    "    Create binary image from a color image by thresholding S and H color channels, as well as the gradient along X axis\n",
    "    \n",
    "    Input:\n",
    "        img - color image\n",
    "        s_thresh - tuple of minimal and maximal allowable values in S color channel\n",
    "        l_thresh - tuple of minimal and maximal allowable values in L color channel\n",
    "        sx_theshold - tuple of minimal and maximal allowable values of gradient along X axis\n",
    "        \n",
    "    Output: binary image\n",
    "    \"\"\"\n",
    "    \n",
    "    img = np.copy(img)\n",
    "    \n",
    "    # Convert to HLS color space and separate the H channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # compute gradient along X axis using Sobel operator\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) \n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold X gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "        \n",
    "    # Threshold S color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold H color channel\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh[0]) & (l_channel <= l_thresh[1])] = 1\n",
    "    \n",
    "    # Combine binary images\n",
    "    combined = np.zeros_like(s_binary)\n",
    "    combined[(sxbinary == 1) | ((s_binary == 1) & (l_binary == 1))] = 1\n",
    "    \n",
    "    return np.uint8(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_dir = 'output_images/binary_images/'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    \n",
    "# Make a list of undistorted images\n",
    "images = glob.glob('output_images/undistorted_images/*.jpg')\n",
    "\n",
    "# Create binary image from each undistorted image\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    thresholded = create_binary_image(img, s_thresh=(100, 255))\n",
    "    mpimg.imsave(out_dir+fname.split('\\\\')[-1], thresholded, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Apply a perspective transform to rectify binary image (\"birds-eye view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create perspective transform matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define 4 source points \n",
    "src = np.float32([[609,439],[669,439],\n",
    "                  [1046,673],[257,673]])\n",
    "        \n",
    "# define 4 destination points \n",
    "x1 = 300 \n",
    "y1 = 0\n",
    "x2 = 980 \n",
    "y2 = 720\n",
    "dst = np.float32([[x1,y1],[x2,y1],[x2,y2],[x1,y2]])\n",
    "        \n",
    "# compute perspective transform matrix M\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "# compute inverse perspective transform matrix Minv\n",
    "Minv = cv2.getPerspectiveTransform(dst, src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply perspective transform to the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create output directories\n",
    "\n",
    "# directory of images after perspective transform\n",
    "if not os.path.exists('output_images/perspective_transform'):\n",
    "    os.makedirs('output_images/perspective_transform')\n",
    "    \n",
    "# directory of original images with the bounding lines of pespective transform     \n",
    "if not os.path.exists('output_images/binary_images_lines'):\n",
    "    os.makedirs('output_images/binary_images_lines')\n",
    "    \n",
    "# directory of transformed images with the bounding lines of pespective transform \n",
    "if not os.path.exists('output_images/perspective_transform_lines'):\n",
    "    os.makedirs('output_images/perspective_transform_lines')\n",
    "    \n",
    "# Make a list of binary images\n",
    "images = glob.glob('output_images/binary_images/*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    # apply perspective transform\n",
    "    img_color = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img_color,cv2.COLOR_BGR2GRAY)\n",
    "    warped = cv2.warpPerspective(img, M, img.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    mpimg.imsave('output_images/perspective_transform/'+fname.split('\\\\')[-1], warped, cmap='gray')\n",
    "    \n",
    "    # create an image with the bounding lines of perspective transform\n",
    "    cv2.polylines(img_color, np.int32([src]), isClosed=True, color=(255,0,0), thickness=2)\n",
    "    mpimg.imsave('output_images/binary_images_lines/'+fname.split('\\\\')[-1], img_color)\n",
    "\n",
    "    # apply perspective transform to the the image with the bounding lines of perspective transform\n",
    "    warped_lines = cv2.warpPerspective(img_color, M, img_color.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    mpimg.imsave('output_images/perspective_transform_lines/'+fname.split('\\\\')[-1], warped_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect lane pixels and fit to find the lane boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose the number of sliding windows\n",
    "nwindows = 20 \n",
    "\n",
    "# Set the width of the windows +/- margin\n",
    "margin = 130  \n",
    "\n",
    "# Set minimum number of pixels found to recenter window\n",
    "minpix = 10 \n",
    "\n",
    "# Define conversions in x and y from pixels space to meters\n",
    "ym_per_pix = 51/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/650 # meters per pixel in x dimension\n",
    "\n",
    "# Smoothing parameter\n",
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class that represents a detected line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self, current_fit, x, y):\n",
    "        \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = current_fit \n",
    "        \n",
    "        # x coordinates of the points that are assigned to the line\n",
    "        self.x = x \n",
    "        \n",
    "        # y coordinates of the points that are assigned to the line\n",
    "        self.y = y\n",
    "        \n",
    "    def compute_x(self, y_values):\n",
    "        # compute x value of the fitted line given its y value\n",
    "        return self.current_fit[0]*y_values**2 + self.current_fit[1]*y_values + self.current_fit[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions of the pipeline for finding lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_lane_base(img):\n",
    "    \"\"\"\n",
    "    Find line base\n",
    "    Input: grayscale image\n",
    "    Output: x coordinates of the base of left and right lines\n",
    "    \"\"\"\n",
    "    \n",
    "    # Take a histogram of the bottom part of the image\n",
    "    histogram = np.sum(img[img.shape[0]-200:,:], axis=0)\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    return leftx_base, rightx_base\n",
    "\n",
    "def track_lane(img, x_base, nonzerox, nonzeroy, out_img, visualize):\n",
    "    \"\"\"\n",
    "    Find entire line using sliding windows\n",
    "    Input:\n",
    "        img - original grayscale image\n",
    "        x_base - x coordinate of the base of the line\n",
    "        nonzerox - array of x coordinates of non-zero points in the image\n",
    "        nonzeroy - array of y coordinates of non-zero points in the image\n",
    "        out_img - color image that is used for visualization\n",
    "        visualize - indicator if the function needs to visualize the detected line\n",
    "    Output:\n",
    "        - Line object of the detected line\n",
    "        - image that visualizes the line \n",
    "    \"\"\"\n",
    "        \n",
    "    # Set height of windows\n",
    "    window_height = np.int(img.shape[0]/nwindows)\n",
    "    \n",
    "    # Current positions to be updated for each window\n",
    "    x_current = x_base\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    lane_inds = []\n",
    "    \n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows-5):\n",
    "        \n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img.shape[0] - window*window_height\n",
    "        win_x_low = x_current - margin\n",
    "        win_x_high = x_current + margin\n",
    "        \n",
    "        if visualize == True:\n",
    "            # Draw the windows on the visualization image\n",
    "            cv2.rectangle(out_img,(win_x_low,win_y_low),(win_x_high,win_y_high),\n",
    "                          (0,255,0), 2) \n",
    "\n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "                     (nonzerox >= win_x_low) &  (nonzerox < win_x_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        lane_inds.append(good_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_inds) > minpix:\n",
    "            x_current = np.int(np.mean(nonzerox[good_inds]))\n",
    "        \n",
    "    # Concatenate the arrays of indices\n",
    "    lane_inds = np.concatenate(lane_inds)\n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    x = nonzerox[lane_inds]\n",
    "    y = nonzeroy[lane_inds]  \n",
    "\n",
    "    # Fit a second order polynomial \n",
    "    fit = np.polyfit(y, x, 2)\n",
    "    \n",
    "    return Line(fit, x, y), out_img\n",
    "\n",
    "def radius_of_curvature(x,y,y_eval):\n",
    "    \"\"\"\n",
    "    Compute fit a curve and compute its radius of curvature at a given point\n",
    "    Input: \n",
    "        x - x coordinates of the points of the curve\n",
    "        y - y coordinates of the points of the curve\n",
    "        y_eval - y cvoordinate where to compute the radius of curvature\n",
    "    Output:\n",
    "        radius of curvature at y_eval\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fit new polynomials to x,y in world space\n",
    "    fit_cr = np.polyfit(y*ym_per_pix, x*xm_per_pix, 2)\n",
    "    \n",
    "    # Calculate the new radii of curvature\n",
    "    return ((1 + (2*fit_cr[0]*y_eval*ym_per_pix + fit_cr[1])**2)**1.5) / np.absolute(2*fit_cr[0])\n",
    "\n",
    "def visualize_lanes(undistorted, y_values, left_fitx, right_fitx):\n",
    "    \"\"\"\n",
    "    Draw a poligon that visualizes lines and drivable area\n",
    "    Input:\n",
    "        undistorted - undistorted image\n",
    "        y_values - y values of the line curves\n",
    "        left_fitx - x values of the left line curve\n",
    "        right_fitx - x values of the right line curve\n",
    "    Output: undistorted image with the visualization of lines and drivable area\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    color_warp = np.zeros_like(undistorted).astype(np.uint8)\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, y_values]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, y_values])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255,0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (undistorted.shape[1], undistorted.shape[0])) \n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    return cv2.addWeighted(undistorted, 1, newwarp, 0.3, 0)\n",
    "\n",
    "def adjust_line(line, nonzerox, nonzeroy):\n",
    "    \"\"\"\n",
    "    Adjust previously detected line to the new video frame\n",
    "    Input:\n",
    "        line - line detected in the previous video frame\n",
    "        nonzerox - array of x coordinates of non-zero points in the video frame\n",
    "        nonzeroy - array of y coordinates of non-zero points in the video frame\n",
    "    Output: Line object if the previously detected line was successfully adjusted to the new video frame, None otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    margin = 50\n",
    "    fit_value = line.current_fit[0]*(nonzeroy**2) + line.current_fit[1]*nonzeroy + line.current_fit[2]\n",
    "    lane_inds = ((nonzerox > fit_value - margin) & (nonzerox < fit_value + margin))\n",
    "    x = nonzerox[lane_inds]\n",
    "    y = nonzeroy[lane_inds]\n",
    "    \n",
    "    # Fit a second order polynomial \n",
    "    fit = np.polyfit(y, x, 2)\n",
    "    \n",
    "    # check if both lines are convex or both are concave\n",
    "    # if not, fit the new line from scratch\n",
    "    if fit[0] * line.current_fit[0] > 0:\n",
    "        return Line(fit,x,y)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function of the pipeline for finding lines and visualizing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_line(img, undistorted, prev_lines=[], visualize=False):\n",
    "    \"\"\"\n",
    "    Find lines and visualize them \n",
    "    Input:\n",
    "        img - grayscale image\n",
    "        undistorted - color image after camera calibration\n",
    "        prev_line - list of previously found lines. This list can be emptry of there were are no previously found lines\n",
    "        visualize - indicator if the function needs to visualize intermediate results\n",
    "    Output:\n",
    "        - undistorted image with the visualization of the lines and the drivable area\n",
    "        - left line object\n",
    "        - right line object\n",
    "        - image with the visualization of intermediate results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "        \n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((img, img, img))*255\n",
    "    \n",
    "    if len(prev_lines) > 0:\n",
    "        left_line = adjust_line(prev_lines[0], nonzerox, nonzeroy)\n",
    "        right_line = adjust_line(prev_lines[1], nonzerox, nonzeroy)\n",
    "        \n",
    "    if len(prev_lines) == 0 or left_line is None or right_line is None:        \n",
    "        leftx_base, rightx_base = find_lane_base(img)\n",
    "        left_line, out_img = track_lane(img, leftx_base, nonzerox, nonzeroy, out_img, visualize)\n",
    "        right_line, out_img = track_lane(img, rightx_base, nonzerox, nonzeroy, out_img, visualize)\n",
    "        \n",
    "    # smooth the lines\n",
    "    if len(prev_lines) > 0:\n",
    "        left_line.current_fit = alpha * left_line.current_fit + (1-alpha) * prev_lines[0].current_fit\n",
    "        right_line.current_fit = alpha * right_line.current_fit + (1-alpha) * prev_lines[1].current_fit\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    left_fitx = left_line.compute_x(ploty)\n",
    "    right_fitx = right_line.compute_x(ploty)\n",
    "        \n",
    "    if visualize == True:\n",
    "        # Visualize lanes in image space\n",
    "        out_img[left_line.y, left_line.x] = [255, 0, 0]\n",
    "        out_img[right_line.y, right_line.x] = [0, 0, 255]\n",
    "    \n",
    "        in_image = (left_fitx >= 0) & (left_fitx < img.shape[1])\n",
    "        out_img[ploty[in_image].astype(int), left_fitx[in_image].astype(int)] = [255,255,0]\n",
    "        in_image = (right_fitx >= 0) & (right_fitx < img.shape[1])\n",
    "        out_img[ploty[in_image].astype(int), right_fitx[in_image].astype(int)] = [255,255,0]\n",
    "    \n",
    "    result = visualize_lanes(undistorted, ploty, left_fitx, right_fitx)\n",
    "    \n",
    "    # Compute radius of curvature\n",
    "    y_eval = np.max(ploty)\n",
    "    left_curverad = radius_of_curvature(left_line.x, left_line.y, y_eval)\n",
    "    right_curverad = radius_of_curvature(right_line.x, right_line.y, y_eval)  \n",
    "    curvature = int(round((left_curverad+right_curverad)/2))\n",
    "    string_radius_curvature = 'Radius of Curvature {}(m)'.format(curvature)\n",
    "    \n",
    "    # compute distance to center\n",
    "    distance_to_center = (img.shape[1]/2 - (left_line.compute_x(y_eval) + right_line.compute_x(y_eval))/2)  * xm_per_pix\n",
    "    if distance_to_center > 0:\n",
    "        position = 'right'\n",
    "    else: \n",
    "        position = 'left'\n",
    "    string_position = 'Vehicle is {:.2f}m {} of the center'.format(abs(distance_to_center),position)\n",
    "    \n",
    "    # visualize radius of curvature and distance to center\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(result, string_radius_curvature,(10,70), font, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(result, string_position,(10,140), font, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    if visualize == True:\n",
    "        return result, left_line, right_line, out_img\n",
    "    else:\n",
    "        return result, left_line, right_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find lines and drivable area in the test images and visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create directory of grayscale images with the visualization of lines\n",
    "if not os.path.exists('output_images/fit_lane'):\n",
    "    os.makedirs('output_images/fit_lane')\n",
    "\n",
    "# create directory of undistorted images with the visualization of lines and drivable area\n",
    "if not os.path.exists('output_images/final_image'):\n",
    "    os.makedirs('output_images/final_image')\n",
    "\n",
    "# Make a list of binary images\n",
    "images = glob.glob('output_images/perspective_transform/*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    # read grayscale image after perspective transform\n",
    "    img_color = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img_color,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # read undistorted color image\n",
    "    undistorted = cv2.imread('output_images/undistorted_images/'+fname.split('\\\\')[-1])\n",
    "    undistorted = cv2.cvtColor(undistorted,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # find lines, visualize lines and drivable area, create an image that visualizes intermediate results\n",
    "    result, left_line, right_line, out_img = find_line(img, undistorted, visualize=True)\n",
    "    \n",
    "    # save images\n",
    "    mpimg.imsave('output_images/fit_lane/'+fname.split('\\\\')[-1], out_img)\n",
    "    mpimg.imsave('output_images/final_image/'+fname.split('\\\\')[-1], result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Video 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for finding lines and visualizing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of the lines found in previous frame\n",
    "lines = []\n",
    "\n",
    "def process_image_continuous(image):\n",
    "    \"\"\"\n",
    "    Find lines in a video frame, visualize lines and drivable area\n",
    "    Input: video frame\n",
    "    Output: undistorted video frame with the visualization of lines and drivable area\n",
    "    \"\"\"\n",
    "    \n",
    "    global i, lines\n",
    "    \n",
    "    # undistort image\n",
    "    undistorted = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    \n",
    "    # create thresholded image\n",
    "    thresholded = create_binary_image(undistorted, s_thresh=(100, 255), sx_thresh=(20,100))\n",
    "    \n",
    "    # apply perspective transform\n",
    "    warped = cv2.warpPerspective(thresholded, M, img.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # find and visualize lane\n",
    "    final, left_line, right_line = find_line(warped, undistorted, prev_lines = lines, visualize=False)\n",
    "    \n",
    "    # store lines for the reference in the next video frame\n",
    "    lines = [left_line, right_line]\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find lines in a video stream, visualize lines and drivable area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_videos/project_video.mp4\n",
      "[MoviePy] Writing video output_videos/project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [03:09<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_videos/project_video.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('output_videos'):\n",
    "    os.makedirs('output_videos')\n",
    "      \n",
    "video_name = 'project_video.mp4'\n",
    "clip = VideoFileClip(video_name)\n",
    "clip_lanes = clip.fl_image(process_image_continuous)\n",
    "clip_lanes.write_videofile('output_videos/' + video_name, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output_videos/project_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('output_videos/' + video_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
